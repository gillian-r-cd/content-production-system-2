# backend/core/models/eval_run.py
# åŠŸèƒ½: è¯„ä¼°è¿è¡Œæ¨¡å‹ï¼Œè¿½è¸ªä¸€æ¬¡å®Œæ•´çš„è¯„ä¼°
# ä¸»è¦ç±»: EvalRun
# æ•°æ®ç»“æ„: å­˜å‚¨è¯„ä¼°é…ç½®ã€çŠ¶æ€ã€ç»¼åˆç»“æœ

"""
EvalRun æ¨¡å‹
ä¸€æ¬¡å®Œæ•´çš„è¯„ä¼°è¿è¡Œï¼ŒåŒ…å«å¤šä¸ª EvalTrial
"""

from typing import Optional, List, TYPE_CHECKING

from sqlalchemy import String, Text, JSON, ForeignKey, Float, Integer
from sqlalchemy.orm import Mapped, mapped_column, relationship

from core.models.base import BaseModel

if TYPE_CHECKING:
    from core.models.project import Project
    from core.models.eval_trial import EvalTrial


# è¯„ä¼°è¿è¡ŒçŠ¶æ€
EVAL_RUN_STATUS = {
    "pending": "å¾…è¿è¡Œ",
    "running": "è¿è¡Œä¸­",
    "completed": "å·²å®Œæˆ",
    "failed": "å¤±è´¥",
}

# å¯ç”¨çš„è¯„ä¼°è§’è‰²
EVAL_ROLES = {
    "coach": {
        "name": "æ•™ç»ƒ",
        "description": "ç­–ç•¥è§†è§’ï¼šå†…å®¹æ–¹å‘æ˜¯å¦æ­£ç¡®ï¼Ÿæ„å›¾æ˜¯å¦å¯¹é½ï¼Ÿ",
        "icon": "ğŸ¯",
        "default_dimensions": ["ç­–ç•¥å¯¹é½åº¦", "å®šä½æ¸…æ™°åº¦", "å·®å¼‚åŒ–ç¨‹åº¦"],
    },
    "editor": {
        "name": "ç¼–è¾‘",
        "description": "æ‰‹è‰ºè§†è§’ï¼šå†…å®¹è´¨é‡æ˜¯å¦è¿‡å…³ï¼Ÿç»“æ„æ˜¯å¦åˆç†ï¼Ÿ",
        "icon": "âœï¸",
        "default_dimensions": ["ç»“æ„åˆç†æ€§", "è¯­è¨€è´¨é‡", "å¯è¯»æ€§", "ä¸€è‡´æ€§"],
    },
    "expert": {
        "name": "é¢†åŸŸä¸“å®¶",
        "description": "ä¸“ä¸šè§†è§’ï¼šå†…å®¹æ˜¯å¦å‡†ç¡®ï¼Ÿæ˜¯å¦å…·æœ‰ä¸“ä¸šæ€§ï¼Ÿ",
        "icon": "ğŸ”¬",
        "default_dimensions": ["äº‹å®å‡†ç¡®æ€§", "ä¸“ä¸šæ·±åº¦", "æ•°æ®æ”¯æ’‘", "å¸‚åœºç›¸å…³æ€§"],
    },
    "consumer": {
        "name": "æ¶ˆè´¹è€…",
        "description": "ç”¨æˆ·è§†è§’ï¼šå†…å®¹å¯¹æˆ‘æœ‰ç”¨å—ï¼Ÿèƒ½è§£å†³æˆ‘çš„é—®é¢˜å—ï¼Ÿ",
        "icon": "ğŸ‘¤",
        "default_dimensions": ["éœ€æ±‚åŒ¹é…åº¦", "ç†è§£éš¾åº¦", "ä»·å€¼æ„ŸçŸ¥", "è¡ŒåŠ¨æ„æ„¿"],
    },
    "seller": {
        "name": "å†…å®¹é”€å”®",
        "description": "è½¬åŒ–è§†è§’ï¼šèƒ½æŠŠè¿™ä¸ªå†…å®¹å–å‡ºå»å—ï¼Ÿ",
        "icon": "ğŸ’°",
        "default_dimensions": ["ä»·å€¼ä¼ è¾¾", "éœ€æ±‚åŒ¹é…", "å¼‚è®®å¤„ç†", "è½¬åŒ–ç»“æœ"],
    },
}


class EvalRun(BaseModel):
    """
    è¯„ä¼°è¿è¡Œ
    
    Attributes:
        project_id: æ‰€å±é¡¹ç›®
        name: è¯„ä¼°åç§°
        config: è¿è¡Œé…ç½®
            - model: AIæ¨¡å‹
            - max_turns: æœ€å¤§å¯¹è¯è½®æ•°
            - roles: ä½¿ç”¨çš„è§’è‰²åˆ—è¡¨
            - input_scope: è¯„ä¼°èŒƒå›´ ("all" / å…·ä½“ block_ids)
        status: è¿è¡ŒçŠ¶æ€
        summary: AI ç»¼åˆè¯Šæ–­
        overall_score: ç»¼åˆè¯„åˆ† (1-10)
        role_scores: å„è§’è‰²è¯„åˆ† {role: score}
        trial_count: Trial æ€»æ•°
        content_block_id: å…³è”çš„ ContentBlock IDï¼ˆevalç»“æœå†™å…¥åˆ°blockï¼‰
    """
    __tablename__ = "eval_runs"

    project_id: Mapped[str] = mapped_column(
        String(36), ForeignKey("projects.id"), nullable=False
    )
    name: Mapped[str] = mapped_column(String(200), default="è¯„ä¼°è¿è¡Œ")
    
    config: Mapped[dict] = mapped_column(
        JSON, default=lambda: {
            "model": "default",
            "max_turns": 8,
            "roles": ["coach", "editor", "expert", "consumer", "seller"],
            "input_scope": "all",  # "all" or list of block_ids
        }
    )
    
    status: Mapped[str] = mapped_column(String(20), default="pending")
    summary: Mapped[str] = mapped_column(Text, default="")
    overall_score: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    role_scores: Mapped[dict] = mapped_column(JSON, default=dict)
    trial_count: Mapped[int] = mapped_column(Integer, default=0)
    
    # å…³è”åˆ° ContentBlockï¼ˆè¯„ä¼°ç»“æœå†™å…¥æ­¤å—ï¼‰
    content_block_id: Mapped[Optional[str]] = mapped_column(
        String(36), nullable=True
    )

    # å…³è”
    project: Mapped["Project"] = relationship("Project")
    trials: Mapped[List["EvalTrial"]] = relationship(
        "EvalTrial", back_populates="eval_run",
        cascade="all, delete-orphan"
    )

    def get_completed_trials(self) -> List["EvalTrial"]:
        """è·å–å·²å®Œæˆçš„ Trial"""
        return [t for t in self.trials if t.status == "completed"]
    
    def calculate_overall_score(self) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        completed = self.get_completed_trials()
        if not completed:
            return 0.0
        
        total = sum(t.overall_score or 0 for t in completed)
        return round(total / len(completed), 2)
